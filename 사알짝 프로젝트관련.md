[정리](https://www.notion.so/b39306c297af4473b5a70e11f2c56eea)

Elastic search  - 정확한 검색 결과 제공 – 요구사항으로 ㄱ
-> 기능개선으로는 자동완성검색, 연관검색어, 키워드와 관련된 카테고리(아직 없지만) 추천, 검색 결과가 없는 키워드에는 인기검색어 추천 가능
무엇을 검색해야 할지 모르는 사용자들에게 좋음, 기능 추가로 사용자의 검색 만족도와 정확도를 높일 수 있음

- Redis
    - [https://zdnet.co.kr/view/?no=20131119174125](https://zdnet.co.kr/view/?no=20131119174125)
        
        레디스의 특징은 '싱글 쓰레드'라는 점이다. 싱글 쓰레드는 1번에 1개의 명령어만 실행할 수 있다. 한 서비스에서 요청된 명령어에 대한 작업이 끝나기 전까진 다른 서비스에서 요청하는 명령을 못 받아들인다. 이 특성 때문에 레디스로 웹서비스를 관리할 경우 절대 쓰면 안 되는 명령어들이 몇 가지 있다고 한다. 저장된 모든 키를 보여주는 명령어(keys)나 모든 데이터를 소거하는 명령어(flushall) 등이다.
        
        강 씨는 모든 키를 보여주거나 플러싱하는 명령어는 테스트 환경이나 소량의 데이터를 관리하는 시스템에서 모니터링하는 용도로만 써야 한다며 실행 대상을 전수처리하기 때문에 점차 데이터를 쌓아가는 환경에서는 운영에 차질을 빚을 정도로 속도가 느려질 것이라고 경고했다.
        
        레디스는 인메모리DB라 빠른 속도가 강점이지만 큰 용량의 데이터를 담기엔 공간 제약이 크다. 그래서 실시간 처리는 인메모리에서, 보관은 디스크 기반 스토리지로 하는 구조가 성능과 효율을 함께 달성할 수 있다. 트위터, 인스타그램, 페이스북처럼 대규모 사용자 기반을 갖춘 인터넷 서비스 업체들도 이런 식으로 서비스를 설계했다
        
        레디스는 32비트 환경에선 최대 3GB 메모리만 사용 가능하고 64비트 시스템에서는 그런 제약이 없어 운영체제(OS)의 가상메모리(스왑)까지 쓴다. 하지만 이 경우 시스템의 메모리 한계를 인식하지 못해 더 많은 메모리를 요구하다가 문제를 일으킬 수 있어 관리자가 따로 설정을 더해줘야 한다.
        
        레디스에서 디스크에 메모리 상태를 그대로 받아 저장하는(메모리스냅숏) RDB 기능이 레디스 서버 장애요인 99.9%를 차지한다며 원한다면 이 기능을 그냥 꺼 둘 수 있다
        
    
    ✨✨✨ [https://stackoverflow.com/questions/37990784/difference-between-redis-and-kafka](https://stackoverflow.com/questions/37990784/difference-between-redis-and-kafka)
    
    ✨✨✨ [https://rumor1993.github.io/articles/2020-03/Socket.io_분산처리_1](https://rumor1993.github.io/articles/2020-03/Socket.io_%EB%B6%84%EC%82%B0%EC%B2%98%EB%A6%AC_1)
    
    ✨✨✨ [https://socket.io/docs/v4/redis-adapter/](https://socket.io/docs/v4/redis-adapter/)
    
    - 정의
        
        레디스(Redis)는 **Remote Dictionary Server**의 약자로서**, key-value 구조의 비정형 데이터를 저장하고 관리하기 위한 오픈 소스 기반의 DBMS** 입니다.
        
        흔히 사용하는 DBMS와는 다르게 **모든 데이터를 메모리로 불러와서 처리하는 메모리 기반 DBMS**
        
    - 왜 레디스? 딴거아니고
        
        Redis pub-sub은 대부분 여러분이 만든 모든 메시지가 한 번에 모든 소비자들에게 전달되고 데이터는 어디에도 보관되지 않는 화재와 망각 시스템과 같습니다. 당신은 레디스를 기억하는 데 한계가 있어요. 또한, 생산자와 소비자의 수는 레디스의 실적에 영향을 미칠 수 있다.
        
        반면, Kafka는 큐로 사용될 수 있는 높은 처리량의 분산 로그입니다. 여기서는 원하는 수의 사용자가 언제든지 생산하고 소비할 수 있습니다. 또한 큐를 통해 전송된 메시지에 대한 지속성도 제공합니다.
        
        최종 테이크:
        
        Redis 사용:
        
        1. 만약 당신이 화재를 원한다면, 당신이 생산하는 모든 메시지가 소비자들에게 즉시 전달되는 일종의 시스템을 잊어버리세요.
        2. 속도가 가장 중요한 경우.
        3. 데이터 손실을 감당할 수 있다면.
        4. 시스템에서 전송된 메시지를 보관하지 않도록 하려면
        5. 처리될 데이터의 양은 많지 않아요.
        
        카프카 사용:
        
        1. 신뢰성을 원한다면요.
        2. 사용 후에도 전송된 메시지의 복사본을 시스템에 저장하려는 경우
        3. 데이터 손실을 감당할 수 없는 경우
        4. 속도가 큰 문제가 아니라면.
        5. 데이터 크기가 큽니다.
    - 인메모리 데이터베이스
        
        데이터 스토리지의 메인 메모리에 설치되어 운영되는 방식의 데이터베이스 관리 시스템이다. 메모리의 데이터에 접근하면 데이터를 조회할 때 검색 시간이 줄어들며 디스크보다 더 빠르고 더 예측 가능성 성능을 제공
        
    - 장점  (pub sub 말고)
        
        MySql, Oracle 같이 데이터를 영구적으로 저장하기 위한 목적으로 DBMS를 사용할 때는 데이터가 디스크에 저장되었기 때문에 데이터를 읽기 위해 매 번 디스크 I/O 가 발생합니다.
        
        디스크 I/O은 상당히 속도가 느린 작업이기 때문에 잦은 디스크 I/O가 발생한다면, 서버의 성능이 현저히 떨어지게 됩니다.
        
        반면에, **Redis는 모든 데이터를 메모리로 불러오기 때문에 데이터를 접근할 때의 속도가 상당히 빠릅니다. (변수를 선언해 놓고 이에 접근하는 것과 같은 이치)**
        
        또한, 데이터가 key-value 구조로 간단명료하고, 다양한 Collection(자료구조)도 제공되기에 데이터를 Read/Write 하는 것도 손쉽습니다.
        
        그리고 **Redis는 싱글쓰레드를 사용하기 때문에 Redis 자체가 Atomic**하여,
        
        트랜잭션 처리로 부터 비교적 자유롭고 비즈니스 로직에만 집중할 수 있다는 장점도 있습니다.
        
    - 단점
        
        가상 메모리 기법이 아닌, 물리적 메모리에 데이터가 직접 올라가기에 메모리 부족현상이 발생할 수도 있고,
        
        메모리에 데이터가 있기 때문에 서버를 리부팅하게 되면 데이터가 전부 날라가게 된다는 단점도 있습니다.
        
        물론 백업 등을 이용하여 레디스의 데이터들을 영구적으로 관리할 수 있지만, 디스크에 데이터를 write하는 비용이 상당하니 고려할 필요가 있습니다.
        
    - 언제 사용?
        
        보통 Session Management, Look aside Cache, Write Bach 목적으로 자주 사용
        
    - 특징
        - 레디스의 Pub/Sub 시스템은 메시지를 보관(queuing) 하지 않습니다. Publish 하는 시점에 이미 실행한 subscribe 명령으로 대기하고 있는 클라이언트들에게만 전달됩니다
        - pub/sub는 메시지 큐와는 특성이 조금 다른데, pub/sub 모델에서는 채널을 subscribe한 모든 subscriber에게 메시지를 전달하기 때문에, 별도로 메시지를 보관하지 않는다는 것입니다.
    
    Kafka와는 달리, Redis에서는 subscribe가 된 상태의 클라이언트만 publish되는 메시지를 받을 수 있다. 쉽게 생각하면, Youtube 채널 구독과 비슷하다. 구독과 좋아요를 누르면, 나중에 새로운 글이 올라오면 노티가 올텐데, 구독중인 상태의 채널에 신규 콘텐츠가 올라오면 노티를 받을 수 있는 것과 같다.
    
    # **단기 메시지: Redis**
    
    Redis의 메모리 내 데이터베이스는 지속성이 필요하지 않은 단기 메시지가 있는 사용 사례에 거의 완벽합니다. 매우 빠른 서비스와 인메모리 기능을 제공하기 때문에 Redis는 지속성이 그다지 중요하지 않고 약간의 손실을 허용할 수 있는 단기 보존 메시지에 대한 완벽한 후보입니다. 5.0에서 Redis 스트림이 출시되면서 일대다 사용 사례의 후보이기도 합니다. 이는 제한 사항과 오래된 pub-sub 기능으로 인해 확실히 필요했습니다.
    
    `PUBLISH channel message` 명령은 먼저 channel을 Hash table에서 channel을 찾고, 리스트에 저장되어 있는 클라이언트들에게 하나씩 메시지를 보낸다.
    
    Snapshot : 스냅샷은 RDB에서도 사용하고 있는 어떤 특정 시점의 데이터를 DISK에 옮겨담는 방식을 뜻합니다. Blocking 방식의 SAVE와 Non-blocking 방식의 BGSAVE 방식이 있습니다.
    
    AOF : Redis의 모든 write/update 연산 자체를 모두 log 파일에 기록하는 형태입니다. 서버가 재시작할 시 write/update를 순차적으로 재실행, 데이터를 복구합니다.
    
    레디스 공식문서에서의 권장사항은 RDBMS의 rollback 시스템같이 두 방식을 혼용해서 사용하는 것입니다. 주기적으로 snapshot으로 벡업하고 다음 snapshot까지의 저장을 AOF 방식으로 수행하는 것이죠.
    
    Why Redis?
    [Socket.io](http://socket.io/) only handles distributing messages, if people disconnect from the chat they will miss any subsequent messages and when anyone connects there will see no history ... so we need a place to store messages for retrieval.
    
    Top 3 reasons why Redis is the clear choice for storing chat messages.
    
    Speed - Redis is much faster than MongoDB, CouchDB or PostgreSQL
    Simple - pushing messages onto a list (set) is the simplest possible way to store a chat history. Given that we can store up to 512Mb per chat and stream chat history to new clients (low http overhead) its an incredibly simple setup!
    Scalable Publish/Subscribe ("pattern") means you can scale out (add more node.js/socket.io servers when you need to serve more clients) Redis can already handle an order of magnitude more than other NoSQL Databases, so your most likely "bottleneck" is node (nuts, hey!?)
    
    레디스는 왜?
    
    [Socket.io](http://socket.io/)은 배포되는 메시지만 처리합니다. 채팅에서 연결이 끊기면 후속 메시지를 놓치게 되고, 연결된 사람이 기록을 볼 수 없게 됩니다. 따라서 검색을 위해 메시지를 저장할 장소가 필요합니다.
    
    Redis가 채팅 메시지를 저장하기 위한 명확한 선택인 3가지 이유
    
    속도 - Redis가 MongoDB, CouchDB 또는 Postgre보다 훨씬 빠릅니다.SQL
    
    단순 - 메시지를 목록(세트)으로 밀어넣는 것이 대화 기록을 저장할 수 있는 가장 간단한 방법입니다. 채팅당 최대 512Mb까지 저장하고 새로운 클라이언트에 채팅 기록을 스트리밍할 수 있다는 점을 감안하면(낮은 HTTP 오버헤드) 매우 간단한 설정입니다!
    
    확장 가능한 게시/구독("node")은 스케일 아웃(클라이언트를 더 많이 제공해야 할 때 node.js/socket.io 서버 추가)을 의미합니다. Redis는 이미 다른 NoSQL 데이터베이스보다 훨씬 많은 수의 서버를 처리할 수 있으므로 "nuts, hey!"가 노드일 가능성이 높습니다.
    
    node에는 cluster라는 것이 있습니다. node는 sigle thread이지만, cluster를 사용하여, 다수의 프로세스에서 서버를 동작시킬 수 있습니다. 하지만 cluster간에는 데이터의 공유가 불가능 합니다. 이렇게 분리된 cluster환경에서 socket.io 을 이용한 프로그래밍을 하다보면, cluster끼리 socket.io 객체를 공유해야 하는 상황이 발생할 수 있습니다. socket.io에서는 redis를 이용한 store를 제공합니다.
    
    redis를 적용하지 않은 상태에서, io.emit과 같이 모든 클라이언트에 메시지를 전송할 경우, 실제로 모든 클라이언트로 전송되는 것이 아닌 해당 프로세스에 접속한 클라이언트에만 전송이 되게 됩니다. 이러한 문제를 해결하기 위해 redis스토어를 사용하게 되면, 모든 프로세스의 클라이언트에게 메시지를 보내게 됩니다.   (3000포트 와 3001포트 서로 메시지공유 안됨)
    
    [https://graykick.tistory.com/5](https://graykick.tistory.com/5)
    
    If you need to emit events to [socket.io](http://socket.io/) instances from a [non-socket.io](http://non-socket.io/) process, you should use socket.io-emitter.
    
    - Why use Redis for WebSocket communication?
        
        사실, WebSocket을 사용하는 것만으로 고객 간에 통신할 수 있는 전송 프로토콜로 충분합니다. 하지만 채팅 실시간 응용프로그램에 어려움을 주는 시나리오가 있습니다.채팅 앱을 고려해 봅시다. 사용자가 처음 연결하면 해당 WebSocket 연결이 응용프로그램(WebSocket 서버) 내에 생성되고 특정 응용프로그램 인스턴스와 연결됩니다. 이러한 WebSocket 연결은 미디어가 사용자 간의 채팅 메시지를 브로드캐스트할 수 있도록 합니다. 이제 새 사용자가 들어오면 새 인스턴스에 연결될 수 있습니다. 따라서 서로 다른 사용자(따라서 각각의 WebSocket 연결)가 서로 다른 인스턴스와 연결되는 시나리오가 있습니다. 그 결과, 그들은 서로 메시지를 교환할 수 없게 됩니다. 이것은 우리의 장난감 채팅 애플리케이션에도 허용되지 않습니다. 그래서 우리는 Redis Pub/Sub 이벤트를 통해 이러한 것들을 원활하게 실행할 수 있어야 합니다.
        
    
    `remoteJoin` allow you to make a given socket join a room from another node.
    
    `socket.join()` is when you have access to the socket object:
    
    ```jsx
    io.on('connect', socket => {
      socket.join('room1');
      
      socket.on('test', () => {
        socket.join('room2');
      });
    });
    ```
    
    `adapter.remoteJoin()` is when you don't have access to the socket object (in a multi server setup, for example):
    
    ```jsx
    io.of('/').adapter.remoteJoin(socketId, 'room1');
    ```
    
    `client.end()`
    
    Forcibly close the connection to the Redis server.  Note that this does not wait until all replies have been parsed.
    If you want to exit cleanly, call `client.quit()` to send the `QUIT` command after you have handled all replies.
    
    `client.end()` is useful for timeout cases where something is stuck or taking too long and you want to start over.
    
- Elastic Stack
    - 왜 검색엔진이 필요할까?
        1. 관계형 데이터베이스는 단순 텍스트매칭에 대한 검색만을 제공
            - 물론 요즘 MySQL 최신 버전에서 n-gram 기반의 Full-text 검색을 지원하지만, 한글 검색의 경우에 아직 많이 빈약한 감이 있습니다.
        2. 텍스트를 여러 단어로 변형하거나 텍스트의 특질을 이용한 동의어나 유의어를 활용한 검색이 가능
        3. 엘라스틱서치에서는 관계형 데이터베이스에서 불가능한 비정형 데이터의 색인과 검색이 가능
            - 이러한 특성은 빅데이터 처리에서 매우 중요하게 생각되는 부분입니다.
        4. 엘라스틱서치에서는 형태소 분석을 통한 자연어 처리가 가능
            - 엘라스틱서치는 다양한 형태소 분석 플러그인을 제공합니다.
        5. 역색인 지원으로 매우 빠른 검색이 가능
            - 역색인에 대한 이야기는 이전 포스팅에 상세히 설명되어 있습니다.
    - 형태소 분석
        
        엘라스틱서치 혹은 솔라와 같은 검색엔진들은 모두 한글에는 성능을 발휘하기 쉽지 않은 검색엔진이다. 그 이유는 한글은 다른 언어와 달리 조사나 어미의 접미사가 명사,동사 등과 결합하기 때문에 기본 형태소분석기로는 분석하기 쉽지 않다. 그렇기 때문에 검색엔진을 한글에 적용하기 위해서 별도의 한글 형태소 분석기가 필요하다.
        
    - 주로 사용하는 분야
        - 사용처 검색 (형태소 분석)
        - 서제스트 랭킹(정렬)
        - 콘텐츠 리스트 표시
        - 페이징
        - 로그 수집
        - 등
    - Full text search
        
        예를 들어, SELECT id FROM board WHERE Content LIKE "%index%"  이런식으로 쿼리를 만들어 사용한다고 하면 모든 행의 문자열을 검색하기 때문에 시간이 오래 걸립니다.
        
        이럴때 사용하는 검색이 Full Text Index입니다. 미리(아님 스케줄로 또는 컴파일할 때,) Content필드의 내용들을 모두 검색해서 검색 불필요 단어(예-영어 : a, the ....)을 뺀 나머지 단어들의 Index를 카타로그로 저장하고 있다가,
        
        Full Text로 질의를 하면, 이때 board테이블의 Contents를 검색하지 않고, 미리 만들어진 카타로그를 통해서 레코드를 찾아 결과를 뿌려주는 방식의 검색입니다.
        
        ---
        
        일반적으로 DB에서 특정 단어가 포함된 레코드를 찾기 위해서 LIKE 를 주로 사용한다. 그러나 LIKE는 '%단어%'와 같이 사용할 때, 인덱스를 사용하지 않기 때문에 데이터가 늘면 늘수록 속도가 느려진다. 또한 LIKE를 여러 필드 (예를 들어, title과 keyword 등)에 동시에 적용하면서 여러 단어를 검색어로 전달하면 쿼리가 복잡해지기도 한다.
        
        ```sql
        select * from board
        where (title like '%학교%' or body like '%학교%')
        and (title like '취업%' or body like '%취업%');
        ```
        
        이를 대체하기 위해서 정규표현식을 적용할 수도 있다. 그러나 정규표현식도 마찬가지로 인덱스를 거치지 않고 풀 스캔(Full Scan)이 일어나기 때문에 느리다.
        
        ```sql
        select * from board
        where (title REGEXP '학교' or body REGEXP '학교')
        and (title REGEXP '취업' or body REGEXP '취업');
        ```
        
        ---
        
        역 인덱스 데이터 구조, 형태소 분석 기능 및 관련성 스코어링의 조합은 full-text search가 일반 데이터베이스 쿼리를 사용하는 문자열 검색보다 유리한 이유입니다.
        
    - Logstash
        - 란?
            - Logstash는 원래 Elasticsearch와 별개로 다양한 데이터 수집과 저장을 위해 개발된 프로젝트였습니다. 데이터의 색인, 검색 기능만을 제공하던 Elasticsearch는 데이터 수집을 위한 도구가 필요했는데, 때마침 Logstash가 출력 API로 Elasticsearch를 지원하기 시작하면서 많은 곳에서 Elasticsearch의 입력 수단으로 Logstash를 사용하기 시작했습니다. Elasticsearch와 Logstash는 서로 통합의 필요성을 느끼고 Logstash가 Elastic에 정식으로 합류하게 되어 하나의 스택으로 출범하게 되었습니다.
            - 다양한 소스(DB, csv 파일 등)의 로그 또는 트랜잭션 데이터를 수집, 집계, 파싱하여 Elasticsearch로 전달
            - 데이터 수집 도구. 다양한 데이터 시스템들로부터 데이터를 수집하고 다시 전송할 수 있은 ETL도구. 모든 데이터 소스가 있는 장비에 설치하여야 한다.
    - 아파치 루씬
        - 역색인 구조의 검색엔진
    - Elasticsearch
        - 란?
            - Logstach로부터 받은 데이터를 검색 및 집계를 하여 필요한 관심 있는 정보를 획득
            - 데이터를 저장하고 쿼리를 하고 검색을 하고 분석을 하는 모든 처리 담당
            - 확장성이 뛰어난 RESTful 검색 및 분석 엔진. 대용량 데이터를 빠르고 실시간으로 저장, 검색 및 분석할 수 있습니다. 기술 탐색 결과 엘라스틱서치에 저장한 데이터를 키바나를 통해서 분석하고 시각화할 수 있다는 점이 매력적이었고, 공식으로 한글 형태소 분석기를 지원하기 때문에 검색 정확도를 높일 수 있다고 생각
                - [https://brunch.co.kr/@kmongdev/7](https://brunch.co.kr/@kmongdev/7)
            - 검색엔진 계속 1위
        - RDBMS와 Elasticsearch 용어 비교
            - 인덱스(Index) | 데이터베이스(Database)
            - 샤드(Shard) | 파티션(Partition)
            - 타입(Type) | 테이블(Table)
            - 문서(Document) | 행(Row)
            - 필드(Field) | 열(Column)
            - 매핑(Mapping) | 스키마(Schema)
            - Query DSL | SQ
        - RDBMS와 Elasticsearch 차이
            1. **관계형 DB**의 CRUD는 클라이언트에서 관계형 DB가 있는 서버에 연결을 맺어 SQL을 날리는 방식이었을 것입니다. 이를테면 JDBC에서 관계형DB가 있는 아이피와 포트를 연결하여 SELECT, INSERT, DELETE등의 쿼리를 날리는 방식이었을 것입니다. **엘라스틱서치**의 경우에는 이와 약간 다릅니다. 데이터를 CRUD하기 위해서 **[RESTful API](https://searchmicroservices.techtarget.com/definition/RESTful-API)라는 방식**을 이용합니다.
            2. RDBMS는 검색조건에 매칭 되는 데이터를 정확하게 리턴하는 반면 Elasticsearch와 같은 Full Text Search 엔진은 검색조건과 관계성/관련성이 높은 데이터를 뽑아 리턴하는 특징이 있다. (_score:xxx와 같이 수치가 출력됨)
            
        - 특징
            - Scale out
                - 샤드를 통해 규모가 수평적으로 늘어날 수 있음
            - 고가용성
                - Replica를 통해 데이터의 안정성을 보장
            - Schema Free
                - JSON 문서를 통해 데이터 검색을 수행하므로 스키마 개념이 없음
            - RESTful
                - 데이터 CURD 작업은 HTTP RESTful API를 통해 수행함
            
            ---
            
            - 역색인구조 Inverted Index [https://the-dev.tistory.com/30](https://the-dev.tistory.com/30)
                - 역색인?
                    - 키워드를 통해 문서를 찾아내는 방식을 말합니다.
                    - 책 뒷편의 색인된 키워드를 이용해 역으로 본문(혹은 문서)을 찾는 방식을 말합니다.
                - 빠르다.
                
                ---
                
                - 예시로 들어보면 일반 색인(forward index)은 책의 목차와 같은 의미이고, 역색인(inverted index)은 책 가장 뒤의 단어 별 색인 페이지와 같다.
        - 왜 Elasticsearch는 검색이 빠를까?
            - 기존RDBMS와 데이터를 저장하는 방식이 다르다
            - 각 value(text)들이 포함된 document들을 나열한다. (몇개 포함되어 잇음)
        - 장점
            - 데이터베이스 대용으로 사용 가능
                - NoSQL 데이터베이스처럼 사용이 가능. 또한 분류가 가능하고 분산 처리를 통해 거의 실시간(NRT)에 데이터 검색이 가능하다.
            - 대량의 비정형 데이터 보관 및 검색 가능 Schemaless
                - 기존 데이터베이스로 처리하기 어려운 대량의 비정형 데이터 검색이 가능하며, 전문 검색(Full Text Search)와 구조 검색 모두를 지원한다. 기본적으로 검색엔진이지만 MongoDB나 Hbase처럼 대용량 스토리지로 사용도 가능.
            - **오픈소스 검색엔진**이다. 활발한 오픈소스 커뮤니티가 ES를 끊임없이 개선하고 발전시키고 있다.
            - 전문 검색(Full text search)
                - 내용 전체를 색인하여 특정단어가 포함된 문서를 검색하는 것이 가능하다.
                - 기능별, 언어별 플러그인을 적용할 수 있다.
            - **통계 분석**
                - 비정형 로그 데이터를 수집하여 통계 분석에 활용할 수 있다. Kibana를 연결하면 실시간으로 로그를 분석하고 시각화할 수 있다
            - **RESTful API**
                - HTTP기반의 RESTful를 활용하고 요청/응답에 JSON을 사용해 개발 언어, 운영체제, 시스템에 관계없이 다양한 플랫폼에서 활용이 가능하다.
            - **Multi-tenancy**
                - 서로 상이한 인덱스일지라도 검색할 필드명만 같으면 여러 인덱스를 한번에 조회할 수 있다.
            - **Document-Oriented**
                - 여러 계층 구조의 문서로 저장이 가능하며, 계층 구조로된 문서도 한번의 쿼리로 쉽게 조회할 수 있다.
            - **역색인(Inverted Index)**
            - **확장성**
                - 분산 구성이 가능하다. 분산 환경에서 데이터는 shard라는 단위로 나뉜다.
            - **분산/확장성/병렬처리**
                - Elasticsearch 구성 시 보통 3개 이상의 노드(Elasticsearch 서버)를 클러스터로 구성하며, 데이터를 샤드(shard)로 저장 시 클러스터 내 다른 호스트에 복사본(replica)을 저장해 놓기 때문에 하나의 노드가 죽거나 샤드가 깨져도 복제되어 있는 다른 샤드를 활용하기 때문에 데이터의 안정성을 보장한다.
                - 또한 데이터의 분산과 병렬처리가 되므로 실시간 검색 및 분석을 할 수 있고, 노드(Elasticsearch 서버)를 수평적으로 늘릴 수 있게 설계되어 있기 때문에 더 많은 용량이 필요한 경우 노드를 클러스터에 추가할 수 있다.
            
            ---
            
            한글형태소 분석기와 키바나의 시각화, 데이터 분석 같은 장점을 활용
            
            ---
            
            - 분산처리를 통해 실시간성으로 빠른 검색이 가능
            - 전문 검색(full text) 검색과 구조 검색 모두를 지원
        - 단점
            - 진입 장벽이 있다
            - Document 간 조인을 수행할 수 없다.(두번 쿼리로 해결 가능)
            - 트랜잭션 및 롤백이 제공되지 않는다.
                - 전체적인 클러스터의 성능 향상을 위해 시스템적으로 비용 소모가 큰 롤백과 트랜잭션을 지원하지 않는다.
            - 실시간 처리가 불가능하다. (색인된 데이터가 1초 뒤에나 검색이 가능하다)
                - 내부적으로 commit과 flush같은 복잡한 과정을 거치기 때문.
            - 데이터의 업데이트를 지원하지 않는다.
                - 업데이트 명령이 올 경우 기존 문서를 삭제하고 새로운 문서를 생성한다. 업데이트에 비해서 많은 비용이 들지만 이를 통해 불변성(Immutable)이라는 이점을 취한다.
        - 일반적으로 사용하는 아키텍처
            - 특정 서버에서 생성되는 데이터를 RDBMS 또는 Non-RDBMS에 저장을 하고, 검색 혹은 분석이 필요한 부분만을 데이터를 추출하여 Elasticsearch에 자동 저장시킨다.
            - 이때 기존 DB에서 Elasticsearch로 자동 저장하는, 즉 ETL 기능을 하는 것이 **Logstash**
            - 
    - Kibana
        - 란?
            - Elasticsearch의 빠른 검색을 통해 데이터를 시각화 및 모니터링
            - 시각화 및 분석을 위한 클라이언트 도구
- Websocket
    
    `WebSocket`을 통해 client(browser)와 server가 양방향 통신을 할 수 있다. `HTTP`통신 같은 경우, client에서 server로의 일방향 request만 가능하다면, `WebSocket`은 양방향 통신이 가능하며, client 와 server가 수시로 통신이 가능하다. 따라서 이 기술을 통해 실시간 채팅과 같은 기능 구현이 가능
    
- Socket.io
    
    Socket.io란 ? 
    
    - 실시간으로 상호작용하는 웹 서비스를 만드는 기술인 WebSocket을 쉽게 사용할 수 있게 해주는 모듈.
    - HTML5 WebSocket도 매우 유용한 기술이지만 오래된 브라우저의 경우 지원하지 않는 경우가 있다. → 브라우저 간 호환이나 이전 버전 호환을 고려하여 Node.js를 위한 강력한 Cross-platform WebSocket API인 Socket.io를 사용하는 것이 바람직하다.
    - 클라이언트와 서버의 양방향 통신을 가능하게 해주는 모듈입니다. socket.io는 통신을 시작할 때, 각 브라우저에 대해서 websocket, pooling, streaming, flash socket 등에서 가장 적절한 방법을 찾아 메시지를 보내줍니다.
    - Namespace와 Room 두가지 방법으로 채팅방을 구현 할 수 있다
    - 메소드
        
        `socket.emit()` : 하나의 client에 정보 전달
        
        `io.emit()` : 연결된 모든 client에 정보 전달
        
        `socket.broadcast.emit()` : 해당 client 제외 모든 연결된 client에 정보 전달
        
        `socket.on()` : client 나 server에서 상대편에서 보내는 정보를 받아준다.
        
        `.on()` 을 통해 정보를 받은 후에 정보를 보낸  쪽에 다시 `acknowledgement`로 feedback줄 수 있음
        
        ```jsx
        socket.on('join', ({username, room}, callback) => {
                const { error, user } = addUser({ id: socket.id, username, room })
        
                if (error) {
                    return callback(error) // acknoledgement. error를 client side로 보냄.
                }
                socket.join(user.room)
        
                socket.emit('message', generateMessage({text: 'Welcome!', username: 'Admin'}))
                socket.broadcast.to(user.room).emit('message', generateMessage({text: `${user.username} has joined!`, username: 'Admin'}))
                io.to(user.room).emit('roomData', {
                    room: user.room,
                    users: getUsersInRoom(user.room)
                })
        
                callback() // acknowledgement without error
            })
        ```
        
    - Namespace
        
        Namespace에 있는 소켓끼리만 통신하는 개념. 예를 들어 같은 ('/') Namespace 에 있는 소켓끼리만 통신이 됨.
        
        NameSpace → Room → Socket
        
        `io.of('/namespace')` 로 접속
        
        ```jsx
        socket = io('http://localhost:3002/namespace');
        ```
        
        특정 namespace로 연결할 수 있다.
        
        기존 연결에서 Namespace를 "전환"할 수 없습니다. 연결되면 특정 Namespace에 연결하고 한 번 변경하면 변경할 수 없습니다.
        
        현재 연결을 삭제하고 새 연결을 사용하여 새 Namespace에 연결할 수 있습니다. 그러나 응용 프로그램에서 Namespace를 전환하려는 경우 Namespace잘못 사용하고 대신 room을 사용해야합니다.
        
        room의 경우 클라이언트는 서버에 room 전환 요청을 보내고 서버는 기존 room에서 사용자를 제거하고 새 room에 추가 할 수 있습니다. 그런 다음 서버에서 특정 room의 모든 연결로 쉽게 브로드 캐스트 할 수 있습니다.
        
        실제로 채팅방은 다른 많은 용도로 사용되지만 채팅 개념을 중심으로 발명되었으므로 구현하려는 채팅방에 완벽하게 적합합니다.
        
        Namespace는 room보다 무거운 무게 구분입니다. 연결시 특정 Namespace에 연결해야하며 연결 중에 변경할 수 없습니다.
        
        반면에 room은 훨씬 유연합니다. 서버는 주어진 연결을 설정하여 언제든지 room에서 연결을 추가하거나 제거 할 수 있으며 연결은 둘 이상의 room에있을 수도 있습니다.
        
        room과 Namespace 모두 해당 컬렉션의 모든 사용자에게 브로드 캐스트를 지원합니다.
        
        Namespace는 기능 채널과 비슷하다고 생각합니다. 따라서 가격 변동에 대한 알림을 받기 위해 "가격"변경 Namespace에 연결하거나 시스템에서 발생하는 상황에 대한 경고를 받거나 메시지를 보내려면 "시스템" Namespace에 연결하고 싶습니다. 시스템에서 사물을 관리합니다.
        
        room은 정보 공유에 관심이있는 임의의 사용자 모음이며, 둘 이상의 room에있을 수 있습니다.
        
        [https://pythonq.com/so/node.js/1560704](https://pythonq.com/so/node.js/1560704)
        
        [https://dev.to/wpreble1/socket-io-namespaces-and-rooms-d5h](https://dev.to/wpreble1/socket-io-namespaces-and-rooms-d5h)
        
        ---
        
        const namespace = io.of('/namespace');이렇게 특정 namespace를 변수로 잡아서 사용할 수 있습니다. io.of()안에 원하는 이름의 namespace를 입력하여 사용하면 됩니다. 중요한 점은 같은 namespace 끼리만 통신이 가능하므로, 클라이언트의 namespace도 맞춰줘야 합니다. namespace는 여러개가 생성이 가능합니다. 따라서 namespace의 장점은 여러개의 채널을 통해서 각각 구분하여 클라이언트와 서버와의 소통이 가능하다는 것입니다.room 기능은 join과 leave 메서드를 활용해서 입장과 퇴장이 가능합니다. socket.adaptar.rooms를 조회해보면, socket이 참여하고 있는 방들을 확인할 수 있습니다.
        
    - Room
        
        `socket.join()`으로 접속하고 `socket.leave()` 로 나간다.
        
    - Namspace vs Room
        - **namespaces are connected to by the client** using `io.connect(urlAndNsp)` (the client will be added to that namespace only if it already exists on the server)
        - **rooms can be joined only on the server side** (although creating an API on the server side to enable clients to join is straightforward)
        - **namespaces can be [authorization protected](https://github.com/LearnBoost/socket.io/wiki/Authorizing)**
        - **authorization is not available with rooms**, but custom authorization could be added to the aforementioned, easy-to-create API on the server, in case one is bent on using rooms
        - **rooms are part of a namespace** (defaulting to the 'global' namespace)
        - **namespaces are always rooted in the global scope**
        
        - So if you need *per-compartment authorization*, `namespace`s might be the easiest route to take
        - if you want hierarchically layered compartments (2 layers max), use a namespace/room combo
        - if your client-side app consists of different parts that (do not themselves care about compartments but) need to be separated from each other, use namespaces.
        
        [https://stackoverflow.com/questions/10930286/socket-io-rooms-or-namespacing](https://stackoverflow.com/questions/10930286/socket-io-rooms-or-namespacing)
        
    - emit cheatsheet
        
        ```
        io.on('connect', onConnect);
        
        function onConnect(socket){
        
          // sending to the client
          socket.emit('hello', 'can you hear me?', 1, 2, 'abc');
        
          // sending to all clients except sender
          socket.broadcast.emit('broadcast', 'hello friends!');
        
          // sending to all clients in 'game' room except sender
          socket.to('game').emit('nice game', "let's play a game");
        
          // sending to all clients in 'game1' and/or in 'game2' room, except sender
          socket.to('game1').to('game2').emit('nice game', "let's play a game (too)");
        
          // sending to all clients in 'game' room, including sender
          io.in('game').emit('big-announcement', 'the game will start soon');
        
          // sending to all clients in namespace 'myNamespace', including sender
          io.of('myNamespace').emit('bigger-announcement', 'the tournament will start soon');
        
          // sending to a specific room in a specific namespace, including sender
          io.of('myNamespace').to('room').emit('event', 'message');
        
          // sending to individual socketid (private message)
          io.to(`${socketId}`).emit('hey', 'I just met you');
        
          // WARNING: `socket.to(socket.id).emit()` will NOT work, as it will send to everyone in the room
          // named `socket.id` but the sender. Please use the classic `socket.emit()` instead.
        
          // sending with acknowledgement
          socket.emit('question', 'do you think so?', function (answer) {});
        
          // sending without compression
          socket.compress(false).emit('uncompressed', "that's rough");
        
          // sending a message that might be dropped if the client is not ready to receive messages
          socket.volatile.emit('maybe', 'do you really need it?');
        
          // specifying whether the data to send has binary data
          socket.binary(false).emit('what', 'I have no binaries!');
        
          // sending to all clients on this node (when using multiple nodes)
          io.local.emit('hi', 'my lovely babies');
        
          // sending to all connected clients
          io.emit('an event sent to all connected clients');
        
        };
        ```
        
    - emit tips
        - 그룹 목록과 그룹 안의 소켓들을 확인하는 법
            
            > io.adapter.rooms
            io.of(네임스페이스).adapter.rooms
            socket.adapter.rooms
            > 
            - but 위의 방법대로 하면 인원 수나 방의 수를 구하는 것이 불안전하기 때문에, 서버상에서 배열을 만들어 받은 아이디를 모아두는 것이 편할 것 (방 안에는 참여한 사람들의 소켓 아이디를 넣어두고 ~)
                
                > [
                    { _id: 'room01', members: ['zero_id', 'aero_id']},
                    { _id: 'room02', members: ['nero_id', 'hero_id']},
                ]
                > 
                - 이런 식으로 저장할 경우 서버가 꺼지지 않는 이상 저 배열은 데이터베이스처럼 동작함.
    - socket.io-redis
        
        # Sending messages from the outside-world
        
        In some cases, you might want to emit events to sockets in Socket.IO namespaces / rooms from outside the context of your Socket.IO processes.
        
        There’s several ways to tackle this problem, like implementing your own channel to send messages into the process.
        
        To facilitate this use case, we created two modules:
        
        - [socket.io-redis](http://github.com/automattic/socket.io-redis)
        - [socket.io-emitter](http://github.com/automattic/socket.io-emitter)
        
        By implementing the Redis `Adapter`:
        
        ```
        var io = require('socket.io')(3000);
        var redis = require('socket.io-redis');
        io.adapter(redis({ host: 'localhost', port: 6379 }));
        ```
        
        you can then `emit` messages from any other process to any channel
        
        ```
        var io = require('socket.io-emitter')();
        setInterval(function(){
          io.emit('time', new Date);
        }, 5000);
        ```
        

node.js 노드가 하나가 아니라 여러개의 프로세스를 이용해서 운영할 때,socket.io를 어떻게 사용해야 할까? 이런 멀티 프로세스를 지원하기 위해서, node.js는 내부적으로 redis store를 지원한다. redis에는 publish/subscribe라는 기능이 있는데, 마치 메세지 큐처럼 메세지를 subscriber로 보낼 수 있는 기능이다.

- JWT
    - 왜 Refresh Token 안씀?
        
        Refresh Token이 탈취된다고 해도 Refresh Token을 무효화 시키면 Access Token을 발급하지 못하게 할 수 있다.
        Access Token의 유효기간을 길게 설정 하면 탈취될 경우 서버 입장에선 무력화 수단이 없기 때문에 Refresh Token을 두는 수고를 들이더라도 사용해야 하는 메리트는 있다고 볼 수 있다.
        
        access 토큰이 노출되는 만큼, refresh 토큰도 노출되어 있으며, 한 단계를 더 거치긴 하지만 공격자 입장에서는 refresh 토큰으로 access 토큰을 얻을 수 있다. 토큰의 유효기간이 1회성 사용 이라면 모를까, 공격자도 사용자 만큼이나 똑같은 조건으로 토큰을 사용할 수 있다.
        Access Token이 만료될 때마다 새롭게 발급하는 과정에서 생기는 HTTP 요청 횟수가 많습니다. 이는 서버의 자원 낭비로 귀결됩니다.
        jwt 방식은 아니지만,  OAuth2 제공자 중에서 github, foursquare은 Refresh Token을 사용하지 않는다고 한다.
        필수가 아닌 선택의 문제.
        
    - 정의
        - JWT는 일반적으로 클라이언트와 서버, 서비스와 서비스 사이 통신 시 권한 인가(Authorization)를 위해 사용하는 토큰이다. URL에대해 안전한 문자열로 구성되어 있기 때문에 HTTP 어디든(URL, Header, ...) 위치할 수 있다.
        - JWT는 URL, Cookie, Header와 같이 사용할 수 있는 문자가 제한된 환경에서 정보를 주고받을 수 있게 하는 데이터 표현 형식(Format)이다. 그런데 실제 우리가 JWT를 이용한 서명(Sign)이나 암호화(Encryption)에 대한 명세는 JWT 하위 JWS(JSON Web Signature)와 JWE(JSON Web Encryption)에 되어있다. 이해하기 쉽게 설명하자면 JWT는 추상화 클래스라(Abstract Class) 할 수 있고, JWS와 JWE는 추상화 클래스를 마저 구현한 콘크리트 클래스(Concrete Class)라고 할 수 있다. 그밖에 JWK(JSON Web Key)는 JSON 형식으로 암호화 키를 표현한 것이고, JWA(JSON Web Algorithm)은 JWS, JWE, JWK에 사용하는 알고리즘에 대한 명세다.
        - 인코딩 된 긴 텍스트 문자열입니다. 이 문자열은 점(.) 기호로 구분된 세 개의 작은 부분으로 구성
        - 당사자간에 정보를 JSON 객체로 안전하게 전송하기 위한 간결하고 독립적인 방법
        
        ---
        
        - **기본 정보**
            
            JSON Web Token (JWT) 은 웹표준 ([RFC 7519](https://tools.ietf.org/html/rfc7519)) 으로서 두 개체에서 JSON 객체를 사용하여 가볍고 자가수용적인 (self-contained) 방식으로 정보를 안전성 있게 전달해줍니다.
            
        - **수많은 프로그래밍 언어에서 지원됩니다**
            
            JWT 는 C, Java, Python, C++, R, C#, PHP, JavaScript, Ruby, Go, Swift 등 대부분의 주류 프로그래밍 언어에서 지원됩니다.
            
        - **자가 수용적 (self-contained) 입니다**
            
            JWT 는 필요한 모든 정보를 자체적으로 지니고 있습니다. JWT 시스템에서 발급된 토큰은, 토큰에 대한 기본정보, 전달 할 정보 (로그인시스템에서는 유저 정보를 나타내겠죠?) 그리고 토큰이 검증됐다는것을 증명해주는 signature 를 포함하고있습니다.
            
        - **쉽게 전달 될 수 있습니다**
            
            JWT 는 자가수용적이므로, 두 개체 사이에서 손쉽게 전달 될 수 있습니다. 웹서버의 경우 HTTP의 헤더에 넣어서 전달 할 수도 있고, URL 의 파라미터로 전달 할 수도 있습니다.
            
        - [https://velopert.com/2389](https://velopert.com/2389)
    - 왜 쓰지?
        - JWT의 넓은 범용성, 무결성 보장, 필요한 값을 자체 포함할 수 있는 성질 때문에 많은 곳에서 JWT를 사용하고 있고, 앞으로 더 많은 곳에서 사용할 수 있을 것이다.
        - HTTP 프로토콜은 Stateless이므로 새 요청은 이전 요청에 대해 아무것도 알지 못합니다.
        - SSS는 HTTP의 Stateless에 대한 솔루션 이었지만 장기적으로 보았을 때 확정성에 위협이 되었습니다.
        - JWT은 인증 및 권한 부여 여부와 같은 두 당사자(발급자 및 대상) 간에 정보를 전송하는 방법. 세션/쿠키 방식과 유사하게 사용자는 Access Token을 HTTP 헤더에 실어 서버로 보냄
    - 장점
        - 서버에 부담을 줄일 수가 있다. 이전에는 세션 정보를 서버 메모리 / 디스크 / 데이터베이스에 저장해 사용자 정보를 갖고 있었지만, JWT를 통해 사용자 정보를 클라이언트가 갖고 있음으로 인해 메모리 비용을 줄일 수 있게 되었다. 사용자가 증가했다고 세션 정보를 관리하기 위해 메모리 용량을 늘릴 필요가 없기 때문이다. → 토큰을 사용하면 세션을 통한 방식과 달리 서버측 부하를 낮출 수 있고 능률적인 접근 권한 관리를 할 수 있으며 분산/클라우드 기반 인프라스트럭처에 더 잘 대응할 수 있습니다.
        - 서버 확장성이 용이하다. 서버를 확장하게 되는 경우 세션 정보를 로드 밸런싱을 통해 꾸준히 유지하기 위한 관리가 필요하지만(DB로 해당 세션 정보를 관리하는 방법도 있지만, 추가되는 서버도 무조건 DB에 연결되야 한다는 제약사항?이 생긴다) , JWT의 경우 그럴 필요가 없다. 세션을 통해 관리하는 것보다 보다 더 용이하게 서버 확장이 가능하다.
        - 별도의 인증 저장소가 필요가 없다. 그래서 인증 서버와 DB에 의존하지 않아도 된다.
        - 중앙의 인증서버, 데이터 스토어에 대한 의존성 없음, 시스템 수평 확장 유리
        - Base64 URL Safe Encoding > URL, Cookie, Header 모두 사용 가능
        
        ---
        
        - 무상태(stateless) 이며 확장성(scalability)이 있다
            
            토큰은 클라이언트사이드에 저장하기 때문에 완전히 stateless 하며, 서버를 확장하기에 매우 적합한 환경을 제공한다. 만약에 세션을 서버측에 저장하고 있고, 서버를 여러대를 사용하여 요청을 분산하였다면, 어떤 유저가 로그인 했을땐, 그 유저는 처음 로그인했었던 그 서버에만 요청을 보내도록 설정을 해야합니다. 하지만, 토큰을 사용한다면, 어떤 서버로 요청이 들어가던, 이제 상관이 없죠.
            
        - 보안성
            
            클라이언트가 서버에 요청을 보낼 때, 더 이상 쿠키를 전달하지 않음으로 쿠키를 사용함으로 인해 발생하는 취약점이 사라집니다. 하지만, 토큰을 사용하는 환경에서도 취약점이 존재 할 수 있으니 언제나 취약점에 대비해야 합니다[(참조)](http://www.kieranpotts.com/blog/token-authentication-security).
            
        - Extensibility (확장성)
            
            여기서의 확장성은, Scalability 와는 또 다른 개념입니다. Scalability 는 서버를 확장하는걸 의미하는 반면, **Extensibility** 는 로그인 정보가 사용되는 분야를 확장하는것을 의미합니다. 토큰을 사용하여 다른 서비스에서도 권한을 공유 할 수 있습니다. 예를 들어서, 스타트업 구인구직 웹서비스인 [로켓펀치](https://www.rocketpunch.com/jobs?specialty=react)에서는 Facebook, LinkedIn, GitHub, Google 계정으로 로그인을 할 수 있습니다. **토큰 기반 시스템에서는, 토큰에 선택적인 권한만 부여하여 발급을 할 수 있습니다** (예를들어서 로켓펀치에서 페이스북 계정으로 로그인을 했다면, 프로필 정보를 가져오는 권한은 있어도, 포스트를 작성 할 수 있는 권한은 없죠)
            
        - 여러 플랫폼 및 도메인
            
            서버 기반 인증 시스템의 문제점을 다룰 때 CORS 에 대하여 언급 했었죠? 어플리케이션과 서비스의 규모가 커지면, 우리는 여러 디바이스를 호환 시키고, 더 많은 종류의 서비스를 제공하게 됩니다. 토큰을 사용한다면, 그 어떤 디바이스에서도, 그 어떤 도메인에서도, 토큰만 유효하다면 요청이 정상적으로 처리 됩니다. 서버측에서 어플리케이션의 응답부분에 다음 헤더만 포함시켜주면 되지요.
            
            `Access-Control-Allow-Origin: *`
            
            이런 구조라면, assets 파일들(이미지, css, js, html 파일 등)은 모두 CDN 에서 제공을 하도록 하고, 서버측에서는 오직 API만 다루도록 하도록 설계 할 수도 있지요.
            
        - [웹 표준](https://tools.ietf.org/html/rfc7519) 기반
            
            토큰 기반 인증 시스템의 구현체인 [JWT](https://jwt.io/)는 웹 표준 [RFC 7519](https://tools.ietf.org/html/rfc7519) 에 등록이 되어있습니다. 따라서 여러 환경에서 지원이 되며 (.NET, Ruby, Java, Node.js, Python, PHP …) 수많은 회사의 인프라스트럭쳐에서 사용 되고 있습니다 (구글, 마이크로소프트 …)
            
        - [https://velopert.com/2350](https://velopert.com/2350)
        
        ---
        
        - 헤더와 페이로드를 가지고 서명 필드를 생성하므로 **데이터 변조 후 재전송**을 막을 수 있습니다.
        - **stateless** 서버를 만들 수 있습니다.
        - **모바일 어플리케이션**에서도 잘 동작합니다.
        - 인증정보를 다른 웹서비스에 전송할 수 있습니다. **(OAuth)**
        
        ---
        
        - 웹이 아닌 모바일에서도 사용 가능
    - 단점
        - JWT 정보를 클라이언트 측에서 갖고 있기 때문에 데이터베이스에서 직접적으로 정보를 변경한 경우 해당 정보를 JWT에 바로 반영 할 수 없으며, 토큰 크기가 커지면 트래픽 크기에 영향을 미칠 수 있다
        - 저장할 필드 수에 따라서 토큰이 커질 수 있다.
        - 토큰이 모든 요청에 대해 전송되면 데이터 트래픽 크기에 영향을 미칠 수 있다.
        - Payload의 정보가 많아지면 네트워크 사용량 증가, 데이터 설계 고려 필요
        - 토큰이 클라이언트에 저장, 서버에서 클라이언트의 토큰을 조작할 수 없음.
        
        인코딩되어있는것이지 암호화되어있는 것은 아니다.
        
        ---
        
        - 여전히 누구나 디코딩이 가능하므로 **데이터 유출**이 발생할 수 있습니다.
            - 다른 사람이 토큰을 decode 하여 데이터 확인 가능
        - 토큰을 탈취당할 경우, 대처하기 어렵다. (유효기간을 기다리거나 token refresh를 해야한다)
        - JWT의 경우, 토큰의 길이가 길기 때문에 요청이 많아질수록 서버 자원의 낭비가 많아진다.
        
        ---
        
        - 토큰을 탈취당한 경우 대처하기 어려움
            - 기본적으로는 서버에서 관리하는게 아니다보니 탈취당한 경우 강제 로그아웃 처리가 불가능
            - 토큰 유효시간이 만료되기 전까지 탈취자는 자유롭게 인증 가능
            - 그래서 유효시간을 짧게 가져가고 refresh token 을 발급하는 방식으로 많이 사용
    - 왜 JSON을 사용할까
        
        SWT (Simple Web Tokens) 및 SAML (Security Assertion Markup Language Token)과 비교할 때 JSON 웹 토큰 (JWT)의 이점에 대해 이야기하겠습니다.
        
        1) JSON이 XML보다 덜 장황하므로 **인코딩 될 때 크기도 작아져** JWT가 SAML보다 더 컴팩트합니다. 따라서 JWT를 HTML 및 HTTP 환경에서 전달하는 것이 좋습니다.
        
        2) 보안 측면에서 SWT는 HMAC 알고리즘을 사용하여 공유 비밀로만 대칭적으로 서명 할 수 있습니다. 그러나 JWT 및 SAML 토큰은 서명을 위해 X.509 인증서 형식의 **공개 / 개인 키 쌍을 사용**할 수 있습니다. 모호한 보안 허점을 도입하지 않고 XML 디지털 서명으로 XML에 서명하는 것은 JSON 서명의 단순성과 비교할 때 매우 어렵습니다.
        
        3) JSON 파서는 객체에 직접 매핑되므로 대부분의 프로그래밍 언어에서 일반적입니다. 반대로, XML에는 자연스러운 문서 간 매핑이 없습니다. 따라서 SAML 어설 션보다 JWT 작업이 쉬워집니다. 사용법과 관련하여 JWT는 인터넷 규모로 사용됩니다. 이는 여러 플랫폼, 특히 **모바일에서 JSON 웹 토큰의 클라이언트 측 처리 용이성을 강조**합니다.
        
    - 언제 JWT을 사용할까?
        
        보통, 회원 인증을 위해 많이 사용합니다. 웹페이지에서 로그인을 하는 경우 혹은 개인 정보에 관련된 통신을 하는 경우에 사용 합니다. 즉, 정보 교류 : 해당 정보가 누가 보낸것인지, 올바른 정보인지 확인을 위해 사용합니다. 실제로 많은 웹 사이트에서 로그인 등의 과정에서 많이 사용중에 있습니다. 물론, 회원 인증 방식에 JWT만 있는 것은 아니고 그중 한 종류
        
        ---
        
        - **회원 인증:** JWT 를 사용하는 가장 흔한 시나리오 입니다. 유저가 로그인을 하면, 서버는 유저의 정보에 기반한 토큰을 발급하여 유저에게 전달해줍니다. 그 후, 유저가 서버에 요청을 할 때 마다 JWT를 포함하여 전달합니다. 서버가 클라이언트에게서 요청을 받을때 마다, 해당 토큰이 유효하고 인증됐는지 검증을 하고, 유저가 요청한 작업에 권한이 있는지 확인하여 작업을 처리합니다.서버측에서는 유저의 세션을 유지 할 필요가 없습니다. 즉 유저가 로그인되어있는지 안되어있는지 신경 쓸 필요가 없고, 유저가 요청을 했을때 토큰만 확인하면 되니, 세션 관리가 필요 없어서 서버 자원을 많이 아낄 수 있죠.
        - **정보 교류**: JWT는 두 개체 사이에서 안정성있게 정보를 교환하기에 좋은 방법입니다. 그 이유는, 정보가 sign 이 되어있기 때문에 정보를 보낸이가 바뀌진 않았는지, 또 정보가 도중에 조작되지는 않았는지 검증할 수 있습니다.
        - 
    - 토큰 기반 시스템의 구현 방식
        
        토큰 기반 시스템의 구현 방식은 시스템마다 크고작은 차이가 있겠지만, 대략적으로 보면 다음과 같다:
        
        1. 유저가 아이디와 비밀번호로 **로그인**을 합니다
        2. 서버측에서 해당 **계정정보를 검증**합니다.
        3. 계정정보가 정확하다면, 서버측에서 유저에게 *signed* **토큰을 발급**해줍니다.*여기서 signed 의 의미는 해당 토큰이 서버에서 정상적으로 발급된 토큰임을 증명하는 signature 를 지니고 있다는 것입니다*
        4. 클라이언트 측에서 전달받은 **토큰을 저장**해두고, 서버에 요청을 할 때 마다, 해당 **토큰을 함께 서버에 전달**합니다.
        5. 서버는 **토큰을 검증**하고, **요청에 응답**합니다.
        
        웹서버에서 토큰을 서버에 전달 할 때에는, HTTP 요청의 헤더에 토큰값을 포함시켜서 전달
        
    - Header, Payload, Signature
        
        ### Header
        
        - `alg`: Signature 를 해싱하기 위한 알고리즘 정보를 갖고 있음
        - `typ`: 토큰의 타입을 나타내는데 없어도 됨. 보통 JWT 를 사용
        
        ---
        
        JWT를 검증하는데 필요한 정보를 가진 JSON 객체는 Base64 URL-Safe 인코딩된 문자열이다. 헤더(Header)는 JWT를 어떻게 검증(Verify)하는가에 대한 내용을 담고 있다. 참고로 alg는 서명 시 사용하는 알고리즘이고, kid는 서명 시 사용하는 키(Public/Private Key)를 식별하는 값이다.
        
        ```
        {
            "alg": "ES256",
            "kid": "Key ID"
        }
        
        ```
        
        위와 같은 JSON 객체를 문자열로 직렬화하고 UTF-8과 Base64 URL-Safe로 인코딩하면 다음과 같이 헤더를 생성할 수 있다.
        
        ```
        Base64URLSafe(UTF-8('{"alg": "ES256","kid": "Key ID"}')) -> eyJhbGciOiJFUzI1NiIsImtpZCI6IktleSBJRCJ9
        
        ```
        
        ### Payload
        
        JWT의 내용이다. 페이로드(Payload)에 있는 속성들을 클레임 셋(Claim Set)이라 부른다. 클레임 셋은 JWT에 대한 내용(토큰 생성자(클라이언트)의 정보, 생성 일시 등)이나 클라이언트와 서버 간 주고 받기로 한 값들로 구성된다.
        
        - `iss`: 토큰 발급자
        - `sub`: 토큰 제목
        - `aud`: 토큰 대상
        - `exp`: 토큰의 만료시간
        - `nbf`: Not Before
        - `iat`: 토큰이 발급된 시간
        - `jti`: JWT의 고유 식별자
        
        ### Signature
        
        - 서버에서 토큰이 유효한지 검증하기 위한 문자열
        - Header + Payload + Secret Key 로 값을 생성하므로 데이터 변조 여부를 판단 가능
        - Secret Key 는 노출되지 않도록 서버에서 잘 관리 필요
        
        ---
        
        점(.)을 구분자로 해서 헤더와 페이로드를 합친 문자열을 서명한 값이다. 서명은 헤더의 alg에 정의된 알고리즘과 비밀 키를 이용해 성성하고 Base64 URL-Safe로 인코딩한다.
        
        ```
        Base64URLSafe(Sign('ES256', '${PRIVATE_KEY}',
        'eyJhbGciOiJFUzI1NiIsImtpZCI6IktleSBJRCJ9.eyJpYXQiOjE1ODYzNjQzMjcsImlzcyI6ImppbmhvLnNoaW4ifQ'))) ->
        MEQCIBSOVBBsCeZ_8vHulOvspJVFU3GADhyCHyzMiBFVyS3qAiB7Tm_MEXi2kLusOBpanIrcs2NVq24uuVDgH71M_fIQGg
        
        ```
        
        ### JWT
        
        점을 구분자로 해서 헤더, 페이로드, 서명을 합치면 JWT가 완성된다.
        
        ```
        eyJhbGciOiJFUzI1NiIsImtpZCI6IktleSBJRCJ9.eyJpYXQiOjE1ODYzNjQzMjcsImlzcyI6ImppbmhvLn
        NoaW4ifQ
        pbmhvLnNoaW4ifQ.MEQCIBSOVBBsCeZ_8vHulOvspJVFU3GADhyCHyzMiBFVyS3qAiB7Tm_ME
        Xi2kLusOBpanIrcs2NVq24uuVDgH71M_fIQGg
        
        ```
        
        이렇게 완성된 JWT는 헤더의 alg, kid 속성과 공개 키를 이용해 검증할 수 있다. 서명 검증이 성공하면 JWT의 모든 내용을 신뢰할 수 있게되고, 페이로드의 값으로 접근 제어나 원하는 처리를 할 수 있게된다.
        
    - Base64 URL-Safe != Base64
        
        (기본적인 거긴 하지만) Base64 URL-Safe 인코딩은 기본 Base64 인코딩에서 '+'(plus)는 '-'(minus)로, '/'(slash)는 '_'(underscore)로 대체된 인코딩 방법이다. 이로 인해서 JWT는 설계 의도대로 URL, Cookie, Header 등 어디에서도 사용될 수 있는 넓은 범용성을 가지게 되었다.
        
    - Header & Payload
        
        JWT의 헤더는 Base64 인코딩 전 항상 UTF-8로 인코딩된 문자열이어야 한다. 이유는 헤더가 꼭 JSON이어야 하고, JSON의 기본 인코딩은 UTF-8이기 때문이다. 정식 명칭은 JOSE(JSON Object Signing and Encryption) Header다. 그렇다면 페이로드는 JSON이 아니어도 괜찮은가라는 의문을 가지게 되는데 페이로드는 일반적으로 JSON을 사용하는 것뿐이지 꼭 JSON이어야 될 이유는 없다. 따라서 페이로드는 헤더와 다르게 Base64 URL-Safe 인코딩만 한다.
        
    - Refresh Token
        
        Refresh Token은 Access Token을 재발급하기 위해 발급한다.
        
        Refresh Token은 만료 기간이 길게 두어야 하기 때문에 보안을 강화하기 위한 다른 방법이 필요하다.
        
    - Access Token
        
        Access Token은 만료 기간을 짧게 두어 탈취되더라도 빠르게 만료되어 보안을 좀 더 강화한다.
        
        만료 기간동안 유효한 Access Token은 여러 개일 수 있다.
        
    - 자체 포함(Self-Contained) & 무상태(Stateless)
        
        JWT는 JWT 자체에 필요한 모든 정보를 담을 수 있다. **헤더는 토큰에 대한 해석 방법**을, **페이로드는 토큰의 내용, 전달할 내용(사용자 정보, 권한, 서비스에 필요한 데이터)**을 자유롭게 담을 수 있으며, **서명으로 헤더와 페이로드가 위 변조 되지 않았다는 것을 검증**할 수 있다. 
        
        서버는 JWT 생성 시 JWT에 검증이나 권한 인가 시 필요한 값을 넣으면 되기 때문에 JWT에 대한 상태를 따로 관리하고 있지 않아도 된다. 예를 들어 토스트 밋업에 대한 JWT 페이로드를 다음과 같이 정의할 수 있다. 토스트 밋업 서버는 JWT 서명 검증 후 권한 확인을 위한 추가적인 통신 없이 roles 속성으로 권한 인가를 진행 할 수 있다.
        
        ```json
        {
            "iss": "meetup.toast.com", <- 발행인
            "iat": 1586364327, <- 발행 시간
            "exp": 1586874996, <- 만료 시간
            "email": "email@email.com", <- 사용자 이메일
            "roles": ["read"] <- 읽기만 가능
        }
        ```
        
    - 공개 키 암호 방식에서 서명(Signature)과 암호화(Encryption)
        
        JWT에서는 기본적으로 공개 키 암호 방식(PKC, Public Key Cryptography)을 사용한다. 비대칭 암호 방식을 이용해 공개 키와 비밀 키를 생성하고 이 키를 상황에 따라 나누어 가지며 통신 시 사용한다. 서명은 데이터의 해싱 값을 비밀 키로 서명하고 다시 공개 키로 서명을 검증(Verify)하는데, 서명은 비밀 키를 가진 곳에서만 할 수 있고 공개 키를 가진 어느 곳에서나 이 데이터의 서명을 검증할 수 있다. 반대로 암호화는 공개 키로 데이터를 암호화(Encrypt)하고 비밀 키로 데이터를 복호화(Decrypt) 한다. 공개 키를 가진 누구나 데이터를 암호화해서 데이터를 보낼 수 있지만 비밀 키를 가진 곳에서만 데이터를 복호화 해 내용을 확인할 수 있다. 여기서 확인할 수 있는 점은 공개 키 암호 방식은 비밀 키로 암호화한 데이터를 공개 키로 복호화 할 수 있고, 반대로 공개키로 암호화 한 데이터는 비밀 키로 복호화할 수 있다는 점이다. 당연히 비밀 키로 암호화한 것을 비밀 키로 풀거나 공개 키로 암호화한 것을 공개 키로 풀 수 없다.
        
    - 보안
        1. `localStorage` 저장 방식
            
            브라우저 저장소에 저장하는 방식이다. Javascript 내 **글로벌 변수**로 **읽기 / 쓰기 접근이 가능**하다.
            
            > 😈 : localStorage 안에 세션 id, refreshToken 또는 accessToken을 저장해두면 **XSS** 취약점을 통해 그 안에 담긴 값을 불러오거나, 불러온 값을 이용해 API 콜을 위조할 수 있다.
            > 
            
            → 
            
            어떤 저장 방식을 택해도 XSS 취약점이 있다면 보안 이슈가 존재한다 (XSS로 API 콜을 보내는 방식으로 다 뚫린다). 그러므로 유저 정보 저장 방식을 바꾸는 것만으로는 방어할 수 없고, 클라이언트와 서버에서 추가적으로 XSS 방어 처리가 필수다.
            
            *예: `<input>`에서 입력된 값이 html / Javascript로 인식되지 않도록 서버에서 escape 처리를 해준다. 또 url을 통해 Javascript를 수행할 수 없도록 라우팅을 꼼꼼하게 관리한다. 다행인 것은 React는 공격자가 string에 html / Javascript를 담아 JSX에 삽입할 경우 자동으로 escape 처리한다. (XSS 방어 처리는 또 다른 주제기에 여기서는 이 정도에서 마무리한다.)*
            
            - XSS 공격
                
                공격자(해커)가 클라이언트 브라우저에 Javascript를 삽입해 실행하는 공격이다. 공격자가 `<input>`을 통해 Javascript를 서버로 전송해 서버에서 스크립트를 실행하거나, url에 Javascript를 적어 클라이언트에서 스크립트 실행이 가능하다면 공격자가 사이트에 스크립트를 삽입해 XSS 공격을 할 수 있다. 이때 공격자는 Javascript를 통해 사이트의 글로벌 변숫값을 가져오거나 그 값을 이용해 사이트인 척 API 콜을 요청할 수도 있다. 다시 말하면 공격자의 코드가 내 사이트의 로직인 척 행동할 수 있다는 거다.
                
            
            [https://velog.io/@yaytomato/프론트에서-안전하게-로그인-처리하기](https://velog.io/@yaytomato/%ED%94%84%EB%A1%A0%ED%8A%B8%EC%97%90%EC%84%9C-%EC%95%88%EC%A0%84%ED%95%98%EA%B2%8C-%EB%A1%9C%EA%B7%B8%EC%9D%B8-%EC%B2%98%EB%A6%AC%ED%95%98%EA%B8%B0)
            
        
        애초에 Jwt 토큰에 포함되는 클레임들은 public 하게 공개되도 상관없는 데이터만 넣어야 합니다. 토큰이 탈취되어 api 요청 등에 악용될 경우를 대비해 토큰 블랙리스트 관리, expire 주기를 짧게 가져가는 등의 방법을 쓰죠
        
        ([https://jsdev.kr/t/jwt/4871](https://jsdev.kr/t/jwt/4871))
        
    - 인증 타입
        
        일반적으로 토큰은 요청 헤더의 Authorization 필드에 담아져 보내집니다.`Authorization: <type> <credentials>`
        
        우리가 궁금해하던 `bearer`는 위 형식에서 `type`에 해당합니다. 토큰에는 많은 종류가 있고 서버는 다양한 종류의 토큰을 처리하기 위해 전송받은 `type`에 따라 토큰을 다르게 처리합니다.
        
        ### Basic
        
        사용자 아이디와 암호를 Base64로 인코딩한 값을 토큰으로 사용한다. (RFC 7617)
        
        ### Bearer
        
        JWT 혹은 OAuth에 대한 토큰을 사용한다. (RFC 6750)
        
        ### Digest
        
        서버에서 난수 데이터 문자열을 클라이언트에 보낸다. 클라이언트는 사용자 정보와 nonce를 포함하는 해시값을 사용하여 응답한다 (RFC 7616)
        
        ### HOBA
        
        전자 서명 기반 인증 (RFC 7486)
        
        ### Mutual
        
        암호를 이용한 클라이언트-서버 상호 인증 (draft-ietf-httpauth-mutual)
        
        ### AWS4-HMAC-SHA256
        
        AWS 전자 서명 기반 인증 [(링크)](https://docs.aws.amazon.com/AmazonS3/latest/API/sigv4-auth-using-authorization-header.html)
        
    
    [https://dingue.tistory.com/15](https://dingue.tistory.com/15)
    

[예제](https://www.notion.so/0b4e26eb695347e2b99bc3ca3567f438)

리액트 라이프사이클

플젝하면서 힘들엇던거?

리덕스 쓸껄 그랬다, 소켓, 협업하는게 힘들었다 (코딩 컨벤션, 변수, 코드 바꾸고 말안하는거) 트렐로,슬랙이용하려햇지만 잘안됐노, Git도~~ git commit message, 회의~

엘라스틱서치로 뭐했어요?/뭐예요

메시지 내용 검색했습니다.    

왜 시큐리티안씀?

배운걸로 카바쌉가능

리액트, 웹팩, 바벨, 엘라스틱서치, jwt, 레디스, 스프링부트 정의 / 장단점 / 왜 씀

Auth 

interceptor쓰고 custom annotation @Auth를 만들어서(role 로 구분), @AuthUser 

security는 필터로쓰고 토큰을 자체적으로 만드는데

